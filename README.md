#### 2017-1
* [DeepStack: Expert-Level Artificial Intelligence in No-Limit Poker](notes/deep-stack.md)[[arxiv](https://128.84.21.199/pdf/1701.01724)]

#### 2016-12
* [Modeling documents with Generative Adversarial Networks  ](notes/adversarial-document-model.md)[[arxiv](https://arxiv.org/abs/1612.09122)]

* [Plug & Play Generative Networks: Conditional Iterative Generation of Images in Latent Space](notes/ppgn.md)[[arxiv](https://arxiv.org/abs/1612.00005)]

#### 2016-11
* [Image-to-image translation using conditional adversarial nets](notes/pix2pix.md)
[[arxiv](https://arxiv.org/abs/1611.07004)][[blog](http://affinelayer.com/pix2pix/index.html)]

#### 2016-10
* CONDITIONAL IMAGE SYNTHESIS WITH AUXILIARY CLASSIFIER GANS [[arxiv](https://arxiv.org/abs/1610.09585)]

* Using Fast Weights to Attend to the Recent Past [[arxiv](https://arxiv.org/abs/1610.06258)]

* Professor Forcing: A New Algorithm for Training Recurrent Networks [[arxiv](https://arxiv.org/abs/1610.09038)][[slideshare](http://2boy.org/~yuta/publications/NIPS2016yomi-poster-Professor-Forcing-tsuboi.pdf)]

#### 2016-9
* HyperNetworks[[arxiv](https://arxiv.org/abs/1609.09106)]

```
relaxed weight-sharing in the time dimension.
```

#### 2016-6
* InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets[[arxiv](https://arxiv.org/abs/1606.03657)]

http://www.inference.vc/infogan-variational-bound-on-mutual-information-twice/

```
- （infoじゃない）GANの損失関数も、相互情報量を使って定式化できる
- GANの損失関数は、相互情報量の下限に対応する
- 本来は上限をminimizeすべきなので、これがGANの学習の不安定性に対応しているのでは？
- info GANの2項目にvariational boundを適用すると下限に対応するので
全体を合わせるとよくわかんないことになってる
```

* [Generative Adversarial Imitation Learning](notes/fig/GAIL170124.png) [[arxiv](https://arxiv.org/abs/1606.03476)] [[speakerdeck](https://speakerdeck.com/takoika/lun-wen-shao-jie-generative-adversarial-imitation-learning)]


#### 2016-6
* Conditional Image Generation with PixelCNN Decoders[[arxiv](https://arxiv.org/abs/1606.05328)][slideshare](http://www.slideshare.net/suga93/conditional-image-generation-with-pixelcnn-decoders)

* Learning to learn by gradient descent by gradient descent[[arxiv](https://arxiv.org/abs/1606.04474)]

* [Tutorial on Variational Autoencoders](notes/vae.md)[[arxiv](https://arxiv.org/abs/1606.05908)]

#### 2016-5
* Unsupervised Learning for Physical Interaction through Video Prediction[[arxiv](https://arxiv.org/abs/1605.07157)][[slideshare](http://www.slideshare.net/yamaryox/unsupervised-learning-for-physical-interaction-through-video-predictionnips2016)]

#### 2016-3
* Adaptive Computation Time for Recurrent Neural Networks [[arxiv](https://arxiv.org/abs/1603.08983)]

#### 2015-11
* Neural Programmer: Inducing Latent Programs with Gradient Descent [[arxiv](https://arxiv.org/abs/1511.04834)]

#### 2015-4
* Anticipating Visual Representations from Unlabeled Video
[[arxiv](https://arxiv.org/abs/1504.08023)]

```
- future frame の カテゴリ を予測する（フレームそのものではない）
- 事前学習したCNNの隠れ層表現を予測する
- multi-outputを予測して、もっともうまく予測できたものの予測誤差が最小となるように学習する
```

#### 2015-2
* Human-level control through deep reinforcement learning [[arxiv](http://files.davidqiu.com/research/nature14236.pdf)]

* Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift [[arxiv](https://arxiv.org/abs/1502.03167)]

#### 2014-10
* Neural Turing Machine[[arxiv](http://arxiv.org/abs/1410.5401)]
